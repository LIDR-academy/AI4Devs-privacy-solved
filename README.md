# AI Privacy course

## Instrucciones

Una vez tienes un contexto general de algunas de las técnicas más relevantes para salvaguardar la privacidad y seguridad de la información en la creación y uso de LLMs, es tu turno de profundizar.

**Investiga sobre cualquiera de las técnicas presentadas en el apartado anterior, o incluso otras que puedan ser relevantes**:
- data privacy vaults
- de-identificación
- generación de datos sintéticos
- LLMs locales
- derechos de autor y copyright
- etc.


Puedes profundizar en los casos de uso en el contexto de LLMs, traer ejemplos textuales y visuales que te ayuden a entender el concepto, citar empresas y herramientas de referencia y/o curar contenido relevante.

Utiliza el asistente que prefieras para aprender sobre esta temática: ChatGPT, Microsoft Copilot, Gemini, Claude...

Eso sí, tendrás que **documentar lo aprendido en español en un formato tipo curso**, en este repositorio Github. 

En este caso el repositorio será colaborativo, iremos aceptando las pull requests para generar una base común. Una vez decidas la temática, *comienza por descargar la última versión del repositorio usando git pull y construye a partir de lo que tus compañer@s ya hayan dejado*. Si no sabes como mantenerte actualizado antes de publicar tu contenido y encontrarte con conflictos, pregunta en el grupo de Whatsapp o revisa documentación sobre git.

Te dejamos una semilla para que puedas comenzar, *introduciendo tu contenido en la categoría correspondiente y linkandolo en el Readme de la raiz, para tener una estructura más clara*. Si necesitas crear carpetas para nuevas categorías, añadir recursos gráficos, etc. hazlo, y no olvides actualizar el Readme de la raiz para que incluya el link a tu contenido. También documenta y cita las referencias bibliográficas y créditos adecuadamente. Si necesitas un ejemplo, puedes usar otros repositorios orientados a contenidos como [System Design Primer](https://github.com/donnemartin/system-design-primer)

Por último, no olvides añadir tu archivo de prompts en la carpeta prompts en formato prompts-tematica-iniciales.md, iniciando con un h1 con tu nombre y el tema. Por ejemplo:

prompts/prompts-enclavesseguros-DGZ.md

# Daniel González - Enclaves Seguros

Prompt:

```

Como un experto en ciberseguridad:

* describe que es el proceso de anonimización o de-identificación de datos para entrenamiento de LLMs.

* describe del proceso para anonimizar los datos

...

```

Este fichero será colaborativo.


Éxitos en tu investigación!



## Índice

### Técnicas de Privacidad y Seguridad
- [Bóvedas de Privacidad de Datos / Data privacy vaults](data-privacy-vaults/README.md)
- [Bóvedas de Privacidad de Datos / Data privacy vaults 2](bovedas_privacidad_datos/README.md)
- [De-identificación](de-identificacion/README.md)
- [Generación de datos sintéticos](generacion_de_datos_sinteticos/README.md)
- [Perturbación de Datos](perturbacion-de-datos/README.md)
- [Filtros de Respuestas](filtros-de-respuestas/README.md)
- [Aprendizaje Federado](aprendizaje-federado/README.md)
- [Privacidad Diferencial](privacidad-diferencial/README.md)
- [Computación Multi-partita Segura](computacion-multi-partita-segura/README.md)
- [Enclaves Seguros](enclaves-seguros/README.md)
- [Cifrado Homomórfico](cifrado-homomorfico/README.md)


### LLMs Locales
- [LLMs Locales](llms-locales-DFO/README.md)
- [LLMs Locales 2](LLMs-LOCALES-TMS/LLMs-LOCALES/README.md)
- [Instalación de LLMs Locales en Cursor](LLMs-locales/res/README.md)


### Evaluación y Pruebas de Seguridad
- [Auditorías](auditorias/README.md)
  - [Ejemplo de auditoria](auditorias/ejemplo_auditoria_Anthropic.md)
- [Red-Teaming y Simulación de Ataques](red-teaming/README.md)
- [Jailbreaking](jailbreaking/README.md)

### Aspectos Legales y Éticos
- [Derechos de Autor](AI4Devs-Copyrights-&-Derechos-de-autor-MADV/README.md)
- [Derechos de Autor en Imágenes Generadas por LLM](derechos_autor_imagenes_generadas_llm/README.md)

### Aplicaciones Prácticas
- [Riesgos de Seguridad y Privacidad con la IA en Desarrollo de Aplicaciones](protocolo-seguridad-software/README.md)
- [Salvaguarda de la Privacidad y Seguridad en Deep Learning y LLMs](privacidad-seguridad-proyectos-tech/privacidad-seguridad-proyectos-tech.md)
