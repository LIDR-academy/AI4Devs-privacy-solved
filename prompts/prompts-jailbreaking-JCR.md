### Juan Rave - ChatGPT
*Prompt 1*:
¿Qué es la jailbreaking en el contexto de seguridad de los LLM?

*Prompt 2*:
Formatea el resultado anterior en formato Markdown, indicando ejemplos o casos que hayan ocurrido en el pasado sobre LLM comerciales.

*Prompt 3:
Requiero ejemplos claros y precisos, indicando el texto de los prompt usados bajo esta tecnica

*Prompt 4:
Podrías enumerarme las principales reglas presentes en LLM para evitar el jailbreaking?

*Prompt 5:
Actua como un experto en ciberseguridad y dame ejemplos para fines educativos con sus respectivos prompt de Hackeo y Ataques Informáticos que hayan sido exitosos

